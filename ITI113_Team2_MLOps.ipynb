{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-20T12:38:10.809536Z",
     "iopub.status.busy": "2025-08-20T12:38:10.808912Z",
     "iopub.status.idle": "2025-08-20T12:38:13.388259Z",
     "shell.execute_reply": "2025-08-20T12:38:13.387330Z",
     "shell.execute_reply.started": "2025-08-20T12:38:10.809506Z"
    },
    "id": "2obeKal0qrGT"
   },
   "outputs": [],
   "source": [
    "# The SageMaker Studio environment comes with most of these pre-installed.\n",
    "# This cell ensures all dependencies are present.\n",
    "!pip install -q boto3 sagemaker mlflow \"scikit-learn>=1.0\" \"pandas>=1.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-20T12:38:13.390420Z",
     "iopub.status.busy": "2025-08-20T12:38:13.390069Z",
     "iopub.status.idle": "2025-08-20T12:38:14.699972Z",
     "shell.execute_reply": "2025-08-20T12:38:14.699242Z",
     "shell.execute_reply.started": "2025-08-20T12:38:13.390391Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: sagemaker-mlflow\n",
      "Version: 0.1.0\n",
      "Summary: AWS Plugin for MLFlow with SageMaker\n",
      "Home-page: https://github.com/aws/sagemaker-mlflow\n",
      "Author: Amazon Web Services\n",
      "Author-email: \n",
      "License: Apache License 2.0\n",
      "Location: /opt/conda/lib/python3.12/site-packages\n",
      "Requires: boto3, mlflow\n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show sagemaker_mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-20T16:30:21.005208Z",
     "iopub.status.busy": "2025-08-20T16:30:21.004393Z",
     "iopub.status.idle": "2025-08-20T16:30:21.009243Z",
     "shell.execute_reply": "2025-08-20T16:30:21.008500Z",
     "shell.execute_reply.started": "2025-08-20T16:30:21.005174Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "\n",
    "# Ensure MLflow is installed\n",
    "try:\n",
    "    import mlflow\n",
    "    import sagemaker_mlflow\n",
    "except ImportError:\n",
    "    print(\"Installing MLflow...\")\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\",  \"boto3==1.37.1\", \"botocore==1.37.1\", \"s3transfer\", \"mlflow==2.22.0\", \"sagemaker-mlflow==0.1.0\"])\n",
    "    import mlflow\n",
    "    import sagemaker_mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-20T16:30:24.828659Z",
     "iopub.status.busy": "2025-08-20T16:30:24.828045Z",
     "iopub.status.idle": "2025-08-20T16:30:24.971477Z",
     "shell.execute_reply": "2025-08-20T16:30:24.970709Z",
     "shell.execute_reply.started": "2025-08-20T16:30:24.828628Z"
    },
    "id": "MlLIOYsVqrGU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder created (or already exists): source\n",
      "Found MLflow Tracking Server ARN: arn:aws:sagemaker:ap-southeast-1:837028399719:mlflow-tracking-server/mlflow-ITI113-Team2\n",
      "S3 Bucket: s3://iti113-team2-bucket/Team2\n",
      "SageMaker Role ARN: arn:aws:iam::837028399719:role/iti113-team2-sagemaker-iti113-team2-domain-iti113-team2-Role\n",
      "MLflow Tracking Server ARN: arn:aws:sagemaker:ap-southeast-1:837028399719:mlflow-tracking-server/mlflow-ITI113-Team2\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "import mlflow\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import make_classification\n",
    "import os\n",
    "\n",
    "# Setup SageMaker session\n",
    "sagemaker_session = sagemaker.Session()\n",
    "sagemaker_client = boto3.client(\"sagemaker\")\n",
    "\n",
    "# --- IMPORTANT: CONFIGURE THESE VARIABLES ---\n",
    "# s3_bucket = sagemaker_session.default_bucket()\n",
    "# ----------------------\n",
    "# UPDATE THESE VARIABLES\n",
    "bucket_name = 'iti113-team2-bucket'\n",
    "base_folder = 'Team2'\n",
    "# ----------------------\n",
    "\n",
    "# Create source folder\n",
    "folder_path = \"source\"\n",
    "os.makedirs(folder_path, exist_ok=True)\n",
    "print(f\"Folder created (or already exists): {folder_path}\")\n",
    "\n",
    "s3_client = boto3.client('s3')\n",
    "\n",
    "data_path = f\"s3://{bucket_name}/{base_folder}\"\n",
    "\n",
    "# Assuming you have your boto3 client and server name\n",
    "tracking_server_name = \"mlflow-ITI113-Team2\"\n",
    "\n",
    "try:\n",
    "    response = sagemaker_client.describe_mlflow_tracking_server(\n",
    "        TrackingServerName=tracking_server_name\n",
    "    )\n",
    "    tracking_server_arn = response['TrackingServerArn']\n",
    "    print(f\"Found MLflow Tracking Server ARN: {tracking_server_arn}\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not find tracking server: {e}\")\n",
    "    tracking_server_arn = None\n",
    "\n",
    "# ARN of your MLflow Tracking Server\n",
    "mlflow_tracking_server_arn = tracking_server_arn\n",
    "\n",
    "# IAM role for SageMaker execution\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "print(f\"S3 Bucket: {data_path}\")\n",
    "print(f\"SageMaker Role ARN: {role}\")\n",
    "print(f\"MLflow Tracking Server ARN: {mlflow_tracking_server_arn}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "### Upload dataset to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-20T16:30:29.873145Z",
     "iopub.status.busy": "2025-08-20T16:30:29.872782Z",
     "iopub.status.idle": "2025-08-20T16:30:29.937403Z",
     "shell.execute_reply": "2025-08-20T16:30:29.936574Z",
     "shell.execute_reply.started": "2025-08-20T16:30:29.873122Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://iti113-team2-bucket/Team2/data\n"
     ]
    }
   ],
   "source": [
    "# Upload to S3\n",
    "s3_client.upload_file('data/Team2Dataset.csv', bucket_name, f'{base_folder}/data/Team2Dataset.csv')\n",
    "s3_path = f\"s3://{bucket_name}/{base_folder}/data/Team2Dataset.csv\"\n",
    "data_s3_uri = os.path.dirname(s3_path) # Log the directory URI\n",
    "\n",
    "print(data_s3_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "### Creating the SageMaker Pipeline\n",
    "\n",
    "Create the pipeline scripts that will be executed as steps in our SageMaker Pipeline.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dQFqaaTJqrGZ"
   },
   "source": [
    "### Pipeline Definition\n",
    "\n",
    "Define the SageMaker Pipeline using the scripts we just created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-20T17:14:01.991758Z",
     "iopub.status.busy": "2025-08-20T17:14:01.991263Z",
     "iopub.status.idle": "2025-08-20T17:14:04.097640Z",
     "shell.execute_reply": "2025-08-20T17:14:04.097087Z",
     "shell.execute_reply.started": "2025-08-20T17:14:01.991728Z"
    },
    "id": "wJVkKxWbqrGZ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to only available Python version: py3\n",
      "INFO:sagemaker.image_uris:Defaulting to only supported image scope: cpu.\n",
      "INFO:sagemaker.image_uris:Defaulting to only available Python version: py3\n",
      "INFO:sagemaker.image_uris:Defaulting to only supported image scope: cpu.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'TrainingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'TrainingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Team2PredictionPipeline is defined and ready to be executed.\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "from sagemaker.workflow.steps import ProcessingStep, TrainingStep, TrainingInput\n",
    "from sagemaker.processing import ScriptProcessor, ProcessingInput, ProcessingOutput\n",
    "from sagemaker.workflow.properties import PropertyFile\n",
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "from sagemaker.workflow.step_collections import RegisterModel\n",
    "from sagemaker.workflow.conditions import ConditionGreaterThanOrEqualTo\n",
    "from sagemaker.workflow.conditions import ConditionNot\n",
    "from sagemaker.workflow.condition_step import ConditionStep\n",
    "from sagemaker.workflow.conditions import ConditionEquals\n",
    "from sagemaker.workflow.functions import JsonGet\n",
    "from sagemaker.workflow.functions import Join\n",
    "from sagemaker.workflow.parameters import ParameterFloat, ParameterString, ParameterInteger\n",
    "from sagemaker.model_metrics import ModelMetrics, FileSource\n",
    "import json\n",
    "\n",
    "# Parameters\n",
    "model_package_group_name = \"Team2PredictorModels\"\n",
    "processing_instance_type = \"ml.t3.medium\"\n",
    "training_instance_type = \"ml.m5.large\"\n",
    "\n",
    "experiment_name_param = ParameterString(name=\"experiment_name\", default_value=\"Team2-Model-Experiment\")\n",
    "accuracy_threshold_param = ParameterFloat(name=\"AccuracyThreshold\", default_value=0.80)\n",
    "\n",
    "model_type_param = ParameterString(name=\"model_type\", default_value=\"logistic_regression\")\n",
    "model_param_grid_param = ParameterString(name=\"model_param_grid\")\n",
    "model_random_state_param = ParameterInteger(name=\"random_state\", default_value=42)\n",
    "model_max_iter_param = ParameterInteger(name=\"max_iter\", default_value=1000)\n",
    "\n",
    "# model_c_param = ParameterFloat(name=\"c_param\", default_value=0.5)\n",
    "# model_n_estimators_param = ParameterInteger(name=\"n_estimators\", default_value=100)\n",
    "# model_max_depth_param = ParameterInteger(name=\"max_depth\", default_value=5)\n",
    "\n",
    "run_name_param = ParameterString(name=\"run_name\", default_value=\"run-default\")\n",
    "\n",
    "#set processing test folder dest\n",
    "s3_process_train_path = f\"s3://{bucket_name}/{base_folder}/processing/train\"\n",
    "s3_process_test_path = f\"s3://{bucket_name}/{base_folder}/processing/test\"\n",
    "s3_process_artifact_path = f\"s3://{bucket_name}/{base_folder}/processing/artifacts\"\n",
    "# print(s3_process_train_path)\n",
    "# print(s3_process_test_path)\n",
    "\n",
    "preprocessor = ScriptProcessor(\n",
    "    image_uri=sagemaker.image_uris.retrieve(\"sklearn\", sagemaker_session.boto_region_name, \"1.2-1\"),\n",
    "    command=[\n",
    "        \"python3\",\n",
    "    ],\n",
    "    instance_type=processing_instance_type,\n",
    "    instance_count=1,\n",
    "    base_job_name=\"preprocess-data\",\n",
    "    role=role,\n",
    ")\n",
    "\n",
    "step_preprocess = ProcessingStep(\n",
    "    name=\"PreprocessData\",\n",
    "    processor=preprocessor,\n",
    "    inputs=[ProcessingInput(source=data_s3_uri, destination=\"/opt/ml/processing/input\")],\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name=\"train\", source=\"/opt/ml/processing/train\", destination=s3_process_train_path),\n",
    "        ProcessingOutput(output_name=\"test\", source=\"/opt/ml/processing/test\", destination=s3_process_test_path),\n",
    "        ProcessingOutput(output_name=\"transformers\", source=\"/opt/ml/processing/artifacts\", destination=s3_process_artifact_path),\n",
    "    ],\n",
    "    code=\"source/preprocess.py\",\n",
    ")\n",
    "\n",
    "# Training Step\n",
    "sklearn_estimator = SKLearn(\n",
    "    entry_point=\"train.py\",\n",
    "    source_dir=\"source\",\n",
    "    framework_version=\"1.2-1\",\n",
    "    instance_type=training_instance_type,\n",
    "    role=role,\n",
    "    hyperparameters={\n",
    "        \"tracking_server_arn\": mlflow_tracking_server_arn,\n",
    "        \"experiment_name\": experiment_name_param,\n",
    "        \"model_type\": model_type_param,\n",
    "        \"model_param_grid\": model_param_grid_param,\n",
    "        \"random_state\": model_random_state_param,\n",
    "        \"max_iter\": model_max_iter_param,\n",
    "        # \"c_param\": model_c_param,\n",
    "        # \"n_estimators\": model_n_estimators_param,\n",
    "        # \"max_depth\": model_max_depth_param,\n",
    "        \"model_output_path\": \"/opt/ml/model\",\n",
    "        \"run_name\": run_name_param,\n",
    "    },\n",
    "    py_version=\"py3\",\n",
    "    requirements=\"source/requirements.txt\"\n",
    ")\n",
    "\n",
    "step_train = TrainingStep(\n",
    "    name=\"TrainModel\",\n",
    "    estimator=sklearn_estimator,\n",
    "    inputs={\n",
    "        \"train\": TrainingInput(\n",
    "            s3_data=step_preprocess.properties.ProcessingOutputConfig.Outputs[\"train\"].S3Output.S3Uri,\n",
    "            content_type=\"text/csv\",\n",
    "        )\n",
    "    },\n",
    ")\n",
    "\n",
    "# Evaluation Step\n",
    "evaluation_processor = ScriptProcessor(\n",
    "    image_uri=sagemaker.image_uris.retrieve(\"sklearn\", sagemaker_session.boto_region_name, \"1.2-1\"),\n",
    "    command=['python3'],\n",
    "    instance_type=processing_instance_type,\n",
    "    instance_count=1,\n",
    "    base_job_name=\"evaluate-model\",\n",
    "    role=role,\n",
    ")\n",
    "\n",
    "evaluation_report = PropertyFile(\n",
    "    name=\"EvaluationReport\", output_name=\"evaluation\", path=\"evaluation.json\"\n",
    ")\n",
    "\n",
    "step_eval = ProcessingStep(\n",
    "    name=\"EvaluateModel\",\n",
    "    processor=evaluation_processor,\n",
    "    inputs=[\n",
    "        ProcessingInput(\n",
    "            source=step_train.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "            destination=\"/opt/ml/processing/model\",\n",
    "        ),\n",
    "        ProcessingInput(\n",
    "            source=step_preprocess.properties.ProcessingOutputConfig.Outputs[\"test\"].S3Output.S3Uri,\n",
    "            destination=\"/opt/ml/processing/test\",\n",
    "        ),\n",
    "    ],\n",
    "    outputs=[ProcessingOutput(output_name=\"evaluation\", source=\"/opt/ml/processing/evaluation\")],\n",
    "    code=\"source/evaluate.py\",  # SageMaker will handle uploading and running this script\n",
    "    job_arguments=[  # Pass arguments here instead of in command\n",
    "        \"--model-path\", \"/opt/ml/processing/model\",\n",
    "        \"--test-path\", \"/opt/ml/processing/test\",\n",
    "        \"--output-path\", \"/opt/ml/processing/evaluation\",\n",
    "        \"--model-package-group-name\", model_package_group_name,\n",
    "        \"--region\", \"ap-southeast-1\",\n",
    "    ],\n",
    "    property_files=[evaluation_report],\n",
    ")\n",
    "\n",
    "\n",
    "model_metrics_report = ModelMetrics(\n",
    "    model_statistics=FileSource(\n",
    "        s3_uri=step_eval.properties.ProcessingOutputConfig.Outputs[\"evaluation\"].S3Output.S3Uri,\n",
    "        content_type=\"application/json\"\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "# RegisterModel step (always defined, but executed conditionally)\n",
    "step_register_new = RegisterModel(\n",
    "    name=\"RegisterNewModel\",\n",
    "    estimator=sklearn_estimator,\n",
    "    model_data=step_train.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "    content_types=[\"application/json\"],\n",
    "    response_types=[\"application/json\"],\n",
    "    inference_instances=[\"ml.t2.medium\"],\n",
    "    transform_instances=[\"ml.m5.large\"],\n",
    "    model_package_group_name=\"Team2PredictorModels\",\n",
    "    model_metrics=model_metrics_report,\n",
    "    approval_status=\"PendingManualApproval\",\n",
    ")\n",
    "\n",
    "step_register_better_model = RegisterModel(\n",
    "    name=\"RegisterBetterModel\",\n",
    "    estimator=sklearn_estimator,\n",
    "    model_data=step_train.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "    content_types=[\"application/json\"],\n",
    "    response_types=[\"application/json\"],\n",
    "    inference_instances=[\"ml.t2.medium\"],\n",
    "    transform_instances=[\"ml.m5.large\"],\n",
    "    model_package_group_name=\"Team2PredictorModels\",\n",
    "    model_metrics=model_metrics_report,\n",
    "    approval_status=\"PendingManualApproval\",\n",
    ")\n",
    "\n",
    "\n",
    "# Conditions: check accuracy > threshold OR no model exists\n",
    "cond_accuracy = ConditionGreaterThanOrEqualTo(\n",
    "    left=JsonGet(\n",
    "        step_name=step_eval.name,\n",
    "        property_file=evaluation_report,\n",
    "        json_path=\"accuracy\"\n",
    "    ),\n",
    "    right=accuracy_threshold_param\n",
    ")\n",
    "\n",
    "cond_no_registered = ConditionEquals(\n",
    "    left=JsonGet(\n",
    "        step_name=step_eval.name,\n",
    "        property_file=evaluation_report,\n",
    "        json_path=\"baseline_exists\" # Check the key added to the report\n",
    "    ),\n",
    "    right=False # Condition is TRUE if baseline_exists is False\n",
    ")\n",
    "\n",
    "# Outer step: Check if model is better\n",
    "step_cond_accuracy = ConditionStep(\n",
    "    name=\"CheckAccuracy\",\n",
    "    conditions=[cond_accuracy],\n",
    "    if_steps=[step_register_better_model], # Register model if accuracy is high\n",
    "    else_steps=[],\n",
    ")\n",
    "\n",
    "# Checks for existence of registered model first\n",
    "step_cond_no_registered = ConditionStep(\n",
    "    name=\"CheckIfModelExists\",\n",
    "    conditions=[cond_no_registered],\n",
    "    if_steps=[step_register_new],  # Register model if no baseline exists\n",
    "    else_steps=[step_cond_accuracy],\n",
    ")\n",
    "\n",
    "\n",
    "# Define Pipeline\n",
    "# pipeline = Pipeline(\n",
    "#     name=\"Team2PredictionPipeline\",\n",
    "#     parameters=[experiment_name_param, accuracy_threshold_param, model_type_param, model_c_param, model_n_estimators_param, model_max_depth_param, run_name_param],\n",
    "#     steps=[step_preprocess, step_train, step_eval, step_cond_no_registered] # Use the 'no registered model' check as the primary condition step\n",
    "# )\n",
    "\n",
    "# #Test\n",
    "pipeline = Pipeline(\n",
    "    name=\"Team2PredictionPipeline\",\n",
    "    parameters=[experiment_name_param, accuracy_threshold_param, model_type_param, model_param_grid_param, model_random_state_param, model_max_iter_param, run_name_param],\n",
    "    steps=[step_preprocess, step_train] # Use the 'no registered model' check as the primary condition step\n",
    ")\n",
    "\n",
    "pipeline.upsert(role_arn=role)\n",
    "print(\"Team2PredictionPipeline is defined and ready to be executed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "#### Experiment 1 - Execute logistic_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-20T17:14:19.002427Z",
     "iopub.status.busy": "2025-08-20T17:14:19.001891Z",
     "iopub.status.idle": "2025-08-20T17:22:20.665972Z",
     "shell.execute_reply": "2025-08-20T17:22:20.665335Z",
     "shell.execute_reply.started": "2025-08-20T17:14:19.002393Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"C\": [0.01, 0.1, 1, 10, 100], \"class_weight\": [null, \"balanced\"], \"penalty\": [\"l1\", \"l2\"], \"solver\": [\"liblinear\"]}\n",
      "Pipeline execution started.\n",
      "arn:aws:sagemaker:ap-southeast-1:837028399719:pipeline/Team2PredictionPipeline/execution/gj43k7hnd5gk\n",
      "Pipeline execution completed.\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "from sagemaker.session import Session\n",
    "import boto3\n",
    "import json\n",
    "\n",
    "pipeline_name = \"Team2PredictionPipeline\"\n",
    "\n",
    "# Load existing pipeline\n",
    "pipeline = Pipeline(name=pipeline_name, sagemaker_session=None)\n",
    "\n",
    "model_param_grid = {\n",
    "    \"C\": [0.01, 0.1, 1, 10, 100],\n",
    "    \"class_weight\": [None,\"balanced\"],\n",
    "    \"penalty\": [\"l1\", \"l2\"],\n",
    "    \"solver\": [\"liblinear\"]\n",
    "}\n",
    "\n",
    "# Correct JSON string for param\n",
    "json_param_grid = json.dumps(model_param_grid)\n",
    "print(json_param_grid)\n",
    "\n",
    "execution = pipeline.start(\n",
    "    parameters={\n",
    "        \"model_type\": \"logistic_regression\",\n",
    "        \"model_param_grid\": json_param_grid,\n",
    "        \"random_state\": 42,\n",
    "        \"max_iter\": 1000,\n",
    "        \"run_name\": \"run-v1\"\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"Pipeline execution started.\")\n",
    "print(execution.arn)\n",
    "try:\n",
    "    execution.wait()\n",
    "    print(\"Pipeline execution completed.\")\n",
    "    execution.describe()\n",
    "except Exception as e:\n",
    "    print(\"Pipeline execution failed:\", str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "#### Experiment 2 - Execute random_forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-20T17:02:18.323009Z",
     "iopub.status.busy": "2025-08-20T17:02:18.322458Z",
     "iopub.status.idle": "2025-08-20T17:10:50.102950Z",
     "shell.execute_reply": "2025-08-20T17:10:50.102252Z",
     "shell.execute_reply.started": "2025-08-20T17:02:18.322984Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"n_estimators\": [100, 200], \"max_depth\": [100, 200, null], \"min_samples_split\": [2, 5], \"class_weight\": [\"balanced\"]}\n",
      "Pipeline execution started.\n",
      "arn:aws:sagemaker:ap-southeast-1:837028399719:pipeline/Team2PredictionPipeline/execution/s08yir3qszwe\n",
      "Pipeline execution completed.\n"
     ]
    }
   ],
   "source": [
    "#random_forest\n",
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "import boto3\n",
    "import json\n",
    "\n",
    "pipeline_name = \"Team2PredictionPipeline\"\n",
    "\n",
    "# Load existing pipeline\n",
    "pipeline = Pipeline(name=pipeline_name, sagemaker_session=None)\n",
    "\n",
    "model_param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [100, 200, None],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'class_weight': ['balanced']\n",
    "}\n",
    "\n",
    "# Correct JSON string for param\n",
    "json_param_grid = json.dumps(model_param_grid)\n",
    "print(json_param_grid)\n",
    "\n",
    "execution = pipeline.start(\n",
    "    parameters={\n",
    "        \"model_type\": \"random_forest\",\n",
    "        \"model_param_grid\": json_param_grid,\n",
    "        \"random_state\": 42,\n",
    "        \"run_name\": \"run-v2\"\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"Pipeline execution started.\")\n",
    "print(execution.arn)\n",
    "try:\n",
    "    execution.wait()\n",
    "    print(\"Pipeline execution completed.\")\n",
    "    execution.describe()\n",
    "except Exception as e:\n",
    "    print(\"Pipeline execution failed:\", str(e))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Team2PredictionPipeline - Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment Tracking"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Experiment 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Experiment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NqKCtZZcqrGa"
   },
   "source": [
    "----\n",
    "### Create Deployment Pipeline\n",
    "\n",
    "Create a separate pipeline that is triggered by a new model registration. This pipeline will deploy the model to a SageMaker endpoint."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nQppkx_5qrGa"
   },
   "source": [
    "----\n",
    "#### Deployment Pipeline Definition\n",
    "\n",
    "This pipeline will be triggered when a new model is registered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T07:30:52.333311Z",
     "iopub.status.busy": "2025-08-18T07:30:52.333019Z",
     "iopub.status.idle": "2025-08-18T07:30:53.409701Z",
     "shell.execute_reply": "2025-08-18T07:30:53.408904Z",
     "shell.execute_reply.started": "2025-08-18T07:30:52.333290Z"
    },
    "id": "4E3VbMYxqrGb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to only available Python version: py3\n",
      "INFO:sagemaker.image_uris:Defaulting to only supported image scope: cpu.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deployment pipeline ARN: arn:aws:sagemaker:ap-southeast-1:837028399719:pipeline/Team2DeployPipeline\n",
      "Deployment pipeline created.\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.workflow.steps import ProcessingStep\n",
    "from sagemaker.processing import ScriptProcessor\n",
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "from sagemaker.workflow.parameters import ParameterString\n",
    "import sagemaker\n",
    "\n",
    "# Define Parameters for the deployment pipeline\n",
    "# This will be provided by the EventBridge trigger\n",
    "model_package_arn_param = ParameterString(name=\"ModelPackageArn\", default_value=\"\")\n",
    "role_param = ParameterString(name=\"ExecutionRole\", default_value=role)\n",
    "endpoint_name_param = ParameterString(name=\"EndpointName\", default_value=\"Team2-predictor-endpoint\")\n",
    "\n",
    "# Create a ScriptProcessor for deployment\n",
    "# Using a more recent scikit-learn version is generally a good idea\n",
    "deploy_processor = ScriptProcessor(\n",
    "    image_uri=sagemaker.image_uris.retrieve(\"sklearn\", sagemaker_session.boto_region_name, version=\"1.2-1\"),\n",
    "    command=[\"python3\"],\n",
    "    instance_type=\"ml.t3.medium\",\n",
    "    instance_count=1,\n",
    "    role=role_param,\n",
    "    base_job_name=\"deploy-registered-model\"\n",
    ")\n",
    "\n",
    "# Define the deployment step that takes the model ARN as an argument\n",
    "step_deploy = ProcessingStep(\n",
    "    name=\"DeployRegisteredModel\",\n",
    "    processor=deploy_processor,\n",
    "    inputs=[ProcessingInput(source=\"source/\", destination=\"/opt/ml/processing/input/scripts\")],\n",
    "    code=\"source/deploy.py\",\n",
    "    job_arguments=[\n",
    "        \"--model-package-arn\", model_package_arn_param,\n",
    "        \"--role\", role_param,\n",
    "        \"--endpoint-name\", endpoint_name_param,\n",
    "        \"--region\", \"ap-southeast-1\" \n",
    "    ]\n",
    ")\n",
    "\n",
    "# Define the independent deployment pipeline\n",
    "deploy_pipeline = Pipeline(\n",
    "    name=\"Team2DeployPipeline\",\n",
    "    parameters=[model_package_arn_param, role_param, endpoint_name_param],\n",
    "    steps=[step_deploy],\n",
    ")\n",
    "\n",
    "# Create or update the pipeline definition\n",
    "# Capture the response which contains the ARN\n",
    "response = deploy_pipeline.upsert(role_arn=role)\n",
    "\n",
    "# Extract the ARN from the response dictionary\n",
    "pipeline_arn = response['PipelineArn']\n",
    "\n",
    "print(f\"Deployment pipeline ARN: {pipeline_arn}\")\n",
    "print('Deployment pipeline created.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Approve registered model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T07:07:23.338826Z",
     "iopub.status.busy": "2025-08-18T07:07:23.338534Z",
     "iopub.status.idle": "2025-08-18T07:07:23.422484Z",
     "shell.execute_reply": "2025-08-18T07:07:23.421761Z",
     "shell.execute_reply.started": "2025-08-18T07:07:23.338803Z"
    }
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "model_group_name = \"Team2PredictorModels\"\n",
    "region = \"ap-southeast-1\"    \n",
    "\n",
    "sagemaker_client = boto3.client(\"sagemaker\", region_name=region)\n",
    "\n",
    "response = sagemaker_client.list_model_packages(ModelPackageGroupName=model_group_name)\n",
    "\n",
    "#approve PendingManualApproval model\n",
    "for model in response[\"ModelPackageSummaryList\"]:\n",
    "    if model[\"ModelApprovalStatus\"] == \"PendingManualApproval\":\n",
    "        print(\"Approving:\", model[\"ModelPackageArn\"])\n",
    "        sagemaker_client.update_model_package(\n",
    "            ModelPackageArn=model[\"ModelPackageArn\"],\n",
    "            ModelApprovalStatus=\"Approved\",\n",
    "            ApprovalDescription=\"Auto-approved after validation.\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trigger deployment pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T07:31:09.937146Z",
     "iopub.status.busy": "2025-08-18T07:31:09.936777Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest approved model ARN: arn:aws:sagemaker:ap-southeast-1:837028399719:model-package/Team2PredictorModels/13\n",
      "Deployment pipeline execution.\n",
      "arn:aws:sagemaker:ap-southeast-1:837028399719:pipeline/Team2DeployPipeline/execution/op938qo8965s\n"
     ]
    }
   ],
   "source": [
    "#manual trigger\n",
    "import boto3\n",
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "\n",
    "# === CONFIGURATION ===\n",
    "region = \"ap-southeast-1\"\n",
    "model_group_name = \"Team2PredictorModels\"\n",
    "pipeline_name = \"Team2DeployPipeline\"  # Your SageMaker pipeline name\n",
    "parameter_name = \"ModelPackageArn\"     # Your pipeline's parameter name\n",
    "\n",
    "# Initialize SageMaker client\n",
    "sagemaker_client = boto3.client(\"sagemaker\", region_name=region)\n",
    "\n",
    "#Find the latest approved model package\n",
    "approved_models = sagemaker_client.list_model_packages(\n",
    "    ModelPackageGroupName=model_group_name,\n",
    "    ModelApprovalStatus=\"Approved\",\n",
    "    SortBy=\"CreationTime\",\n",
    "    SortOrder=\"Descending\",\n",
    "    MaxResults=1\n",
    ")\n",
    "\n",
    "if not approved_models[\"ModelPackageSummaryList\"]:\n",
    "    print(\"‚ùå No approved models found.\")\n",
    "    exit(1)\n",
    "\n",
    "model_package_arn = approved_models[\"ModelPackageSummaryList\"][0][\"ModelPackageArn\"]\n",
    "print(f\"Latest approved model ARN: {model_package_arn}\")\n",
    "\n",
    "# Load existing pipeline\n",
    "pipeline = Pipeline(name=pipeline_name, sagemaker_session=None)\n",
    "\n",
    "execution = pipeline.start(\n",
    "    parameters={\n",
    "        \"ModelPackageArn\": model_package_arn\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"Deployment pipeline execution.\")\n",
    "print(execution.arn)\n",
    "execution.wait()\n",
    "execution.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-20T01:50:54.661972Z",
     "iopub.status.busy": "2025-08-20T01:50:54.661683Z",
     "iopub.status.idle": "2025-08-20T01:50:57.088505Z",
     "shell.execute_reply": "2025-08-20T01:50:57.085665Z",
     "shell.execute_reply.started": "2025-08-20T01:50:54.661948Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n",
      "Creating or updating EventBridge rule: Team2-TriggerDeploymentOnApproval\n",
      "EventBridge rule created successfully!\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "import json\n",
    "\n",
    "# Initialize the EventBridge client\n",
    "events_client = boto3.client(\"events\", region_name=\"ap-southeast-1\")\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "model_group_name = \"Team2PredictorModels\"\n",
    "rule_name = \"Team2-TriggerDeploymentOnApproval\"\n",
    "\n",
    "# Define the event pattern to listen for\n",
    "# This pattern triggers when a model package in your group has its status changed to \"Approved\"\n",
    "event_pattern = {\n",
    "    \"source\": [\"aws.sagemaker\"],\n",
    "    \"detail-type\": [\"SageMaker Model Package State Change\"],\n",
    "    \"detail\": {\n",
    "        \"ModelPackageGroupName\": [model_group_name], \n",
    "        \"ModelApprovalStatus\": [\"Approved\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "target = {\n",
    "    \"Id\": \"Team2DeployPipelineTarget\",\n",
    "    \"Arn\": \"arn:aws:sagemaker:ap-southeast-1:837028399719:pipeline/Team2DeployPipeline\",  # The ARN of the deploy pipeline \n",
    "    \"RoleArn\": role,      # The execution role for the pipeline\n",
    "    \"SageMakerPipelineParameters\": {\n",
    "        \"PipelineParameterList\": [\n",
    "            {\n",
    "                \"Name\": \"ModelPackageArn\",\n",
    "                \"Value\": \"$.detail.ModelPackageArn\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Create or update the EventBridge rule\n",
    "try:\n",
    "    print(f\"Creating or updating EventBridge rule: {rule_name}\")\n",
    "    response = events_client.put_rule(\n",
    "        Name=rule_name,\n",
    "        EventPattern=json.dumps(event_pattern),\n",
    "        State=\"ENABLED\",\n",
    "        Description=\"Triggers Lambda  to deploy model when approved.\"\n",
    "    )\n",
    "\n",
    "    events_client.put_targets(Rule=rule_name, Targets=[target])\n",
    "   \n",
    "    print(\"EventBridge rule created successfully!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error creating rule: {e}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DeployPipeline Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Invoking the Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T13:36:23.803094Z",
     "iopub.status.busy": "2025-08-18T13:36:23.802260Z",
     "iopub.status.idle": "2025-08-18T13:36:27.005358Z",
     "shell.execute_reply": "2025-08-18T13:36:27.004786Z",
     "shell.execute_reply.started": "2025-08-18T13:36:23.803068Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n",
      "Sending payload: {\"data\": [{\"age\": -0.2935741493470144, \"restingBP\": -0.1584962155850272, \"serumcholestrol\": 1.3261537378056152, \"maxheartrate\": 0.980974287811504, \"oldpeak\": 0.2280956321093852, \"gender_0\": 0.0, \"gender_1\": 1.0, \"chestpain_0\": 1.0, \"chestpain_1\": 0.0, \"chestpain_2\": 0.0, \"chestpain_3\": 0.0, \"fastingbloodsugar_0\": 1.0, \"fastingbloodsugar_1\": 0.0, \"restingrelectro_0\": 0.0, \"restingrelectro_1\": 1.0, \"restingrelectro_2\": 0.0, \"exerciseangia_0\": 1.0, \"exerciseangia_1\": 0.0, \"slope_0\": 0.0, \"slope_1\": 0.0, \"slope_2\": 1.0, \"slope_3\": 0.0, \"noofmajorvessels_0\": 0.0, \"noofmajorvessels_1\": 1.0, \"noofmajorvessels_2\": 0.0, \"noofmajorvessels_3\": 0.0}, {\"age\": -1.1336375297753276, \"restingBP\": 0.0084473441211311, \"serumcholestrol\": -1.310244697391503, \"maxheartrate\": 1.566228762537217, \"oldpeak\": -1.5743424498154024, \"gender_0\": 0.0, \"gender_1\": 1.0, \"chestpain_0\": 1.0, \"chestpain_1\": 0.0, \"chestpain_2\": 0.0, \"chestpain_3\": 0.0, \"fastingbloodsugar_0\": 1.0, \"fastingbloodsugar_1\": 0.0, \"restingrelectro_0\": 1.0, \"restingrelectro_1\": 0.0, \"restingrelectro_2\": 0.0, \"exerciseangia_0\": 0.0, \"exerciseangia_1\": 1.0, \"slope_0\": 1.0, \"slope_1\": 0.0, \"slope_2\": 0.0, \"slope_3\": 0.0, \"noofmajorvessels_0\": 1.0, \"noofmajorvessels_1\": 0.0, \"noofmajorvessels_2\": 0.0, \"noofmajorvessels_3\": 0.0}, {\"age\": 1.274544160785837, \"restingBP\": 0.1420021918860578, \"serumcholestrol\": 0.752038319252661, \"maxheartrate\": 1.1858133539655036, \"oldpeak\": -1.5161992858823443, \"gender_0\": 1.0, \"gender_1\": 0.0, \"chestpain_0\": 0.0, \"chestpain_1\": 1.0, \"chestpain_2\": 0.0, \"chestpain_3\": 0.0, \"fastingbloodsugar_0\": 1.0, \"fastingbloodsugar_1\": 0.0, \"restingrelectro_0\": 1.0, \"restingrelectro_1\": 0.0, \"restingrelectro_2\": 0.0, \"exerciseangia_0\": 1.0, \"exerciseangia_1\": 0.0, \"slope_0\": 0.0, \"slope_1\": 1.0, \"slope_2\": 0.0, \"slope_3\": 0.0, \"noofmajorvessels_0\": 0.0, \"noofmajorvessels_1\": 0.0, \"noofmajorvessels_2\": 1.0, \"noofmajorvessels_3\": 0.0}, {\"age\": 0.9945230339763992, \"restingBP\": 0.4425005993571428, \"serumcholestrol\": -0.5850462739561926, \"maxheartrate\": 0.6590843267123617, \"oldpeak\": 1.6816747304358266, \"gender_0\": 0.0, \"gender_1\": 1.0, \"chestpain_0\": 1.0, \"chestpain_1\": 0.0, \"chestpain_2\": 0.0, \"chestpain_3\": 0.0, \"fastingbloodsugar_0\": 1.0, \"fastingbloodsugar_1\": 0.0, \"restingrelectro_0\": 1.0, \"restingrelectro_1\": 0.0, \"restingrelectro_2\": 0.0, \"exerciseangia_0\": 0.0, \"exerciseangia_1\": 1.0, \"slope_0\": 0.0, \"slope_1\": 1.0, \"slope_2\": 0.0, \"slope_3\": 0.0, \"noofmajorvessels_0\": 0.0, \"noofmajorvessels_1\": 1.0, \"noofmajorvessels_2\": 0.0, \"noofmajorvessels_3\": 0.0}, {\"age\": 0.8265103578907367, \"restingBP\": -1.8279318126466109, \"serumcholestrol\": -2.352717431079762, \"maxheartrate\": 1.1858133539655036, \"oldpeak\": -0.5277654990203644, \"gender_0\": 1.0, \"gender_1\": 0.0, \"chestpain_0\": 0.0, \"chestpain_1\": 0.0, \"chestpain_2\": 1.0, \"chestpain_3\": 0.0, \"fastingbloodsugar_0\": 1.0, \"fastingbloodsugar_1\": 0.0, \"restingrelectro_0\": 0.0, \"restingrelectro_1\": 1.0, \"restingrelectro_2\": 0.0, \"exerciseangia_0\": 0.0, \"exerciseangia_1\": 1.0, \"slope_0\": 0.0, \"slope_1\": 0.0, \"slope_2\": 0.0, \"slope_3\": 1.0, \"noofmajorvessels_0\": 0.0, \"noofmajorvessels_1\": 1.0, \"noofmajorvessels_2\": 0.0, \"noofmajorvessels_3\": 0.0}]}\n",
      "\n",
      "Endpoint ARN: arn:aws:sagemaker:ap-southeast-1:837028399719:endpoint/Team2-predictor-endpoint\n",
      "\n",
      "Success!\n",
      "Prediction result: {'predictions': [1, 0, 1, 0, 1]}\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sagemaker\n",
    "\n",
    "# Define endpoint name using the same name deployed\n",
    "endpoint_name = \"Team2-predictor-endpoint\"\n",
    "\n",
    "aws_region = \"ap-southeast-1\"\n",
    "\n",
    "# Create a client to interact with the SageMaker endpoint\n",
    "sagemaker_client = boto3.client(\"sagemaker\", region_name=aws_region)\n",
    "sagemaker_runtime_client = boto3.client(\"sagemaker-runtime\", region_name=aws_region)\n",
    "\n",
    "# 2. Prepare your test data (payload)\n",
    "s3 = boto3.client(\"s3\")\n",
    "sagemaker_session = sagemaker.Session()\n",
    "bucket_name = 'iti113-team2-bucket'\n",
    "base_folder = 'Team2'\n",
    "\n",
    "#test with test.csv\n",
    "s3_process_test_path = f\"s3://{bucket_name}/{base_folder}/processing/test/test.csv\"\n",
    "df = pd.read_csv(s3_process_test_path)\n",
    "df = df.drop(\"target\", axis=1)\n",
    "\n",
    "#send test records\n",
    "sample_data_point = df.head(5).to_dict(orient=\"records\")\n",
    "payload = {\"data\": sample_data_point}\n",
    "print(f\"Sending payload: {json.dumps(payload)}\")\n",
    "\n",
    "# 3. Invoke the endpoint and get the prediction\n",
    "try:\n",
    "    response = sagemaker_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "    endpoint_arn = response[\"EndpointArn\"]\n",
    "    print(\"\\nEndpoint ARN:\", endpoint_arn)\n",
    "\n",
    "    response = sagemaker_runtime_client.invoke_endpoint(\n",
    "        EndpointName=endpoint_name,\n",
    "        ContentType=\"application/json\",\n",
    "        Body=json.dumps(payload) # Serialize the payload to a JSON string\n",
    "    )\n",
    "\n",
    "    # The response body is a streaming object, so we need to read and decode it\n",
    "    response_body = response['Body'].read()\n",
    "    result = json.loads(response_body.decode('utf-8'))\n",
    "\n",
    "    print(\"\\nSuccess!\")\n",
    "    print(f\"Prediction result: {result}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error invoking endpoint: {e}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T13:36:30.357821Z",
     "iopub.status.busy": "2025-08-18T13:36:30.357304Z",
     "iopub.status.idle": "2025-08-18T13:36:30.676826Z",
     "shell.execute_reply": "2025-08-18T13:36:30.676173Z",
     "shell.execute_reply.started": "2025-08-18T13:36:30.357794Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üõë Deleting Team2-predictor-endpoint\n",
      "üõë EndpointConfig 'Team2-predictor-endpoint' already exists. Deleting it...\n",
      "Endpoint deleted.\n"
     ]
    }
   ],
   "source": [
    "#clean up endpoint\n",
    "endpoint_config_name = \"Team2-predictor-endpoint\"\n",
    "try:\n",
    "    sagemaker_client.delete_endpoint(EndpointName=endpoint_name)\n",
    "    print(f\"üõë Deleting {endpoint_name}\")\n",
    "    sagemaker_client.describe_endpoint_config(EndpointConfigName=endpoint_config_name)\n",
    "    print(f\"üõë EndpointConfig '{endpoint_config_name}' already exists. Deleting it...\")\n",
    "    sagemaker_client.delete_endpoint_config(EndpointConfigName=endpoint_config_name)\n",
    "    print(\"Endpoint deleted.\")\n",
    "except sagemaker_client.exceptions.ClientError as e:\n",
    "        # If the resources don't exist, that's fine.\n",
    "    if \"Could not find\" not in str(e):\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### View Cloudwatch Logs\n",
    "\n",
    "You can view the cloudwatch logs. Here is an example for the logs of a previous endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T06:19:04.922948Z",
     "iopub.status.busy": "2025-07-28T06:19:04.922393Z",
     "iopub.status.idle": "2025-07-28T06:19:24.707008Z",
     "shell.execute_reply": "2025-07-28T06:19:24.706169Z",
     "shell.execute_reply.started": "2025-07-28T06:19:04.922921Z"
    }
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "# Enter the name of your SageMaker endpoint\n",
    "endpoint_name = \"heartdisease-predictor-endpoint\"\n",
    "\n",
    "# The log group is created based on the endpoint name\n",
    "log_group_name = f\"/aws/sagemaker/Endpoints/{endpoint_name}\"\n",
    "\n",
    "# Create a CloudWatch Logs client\n",
    "logs_client = boto3.client(\"logs\")\n",
    "\n",
    "print(f\"Searching for logs in: {log_group_name}\\n\")\n",
    "\n",
    "try:\n",
    "    # Find all log streams in the log group, ordered by the most recent\n",
    "    response = logs_client.describe_log_streams(\n",
    "        logGroupName=log_group_name,\n",
    "        orderBy='LastEventTime',\n",
    "        descending=True\n",
    "    )\n",
    "\n",
    "    log_streams = response.get(\"logStreams\", [])\n",
    "\n",
    "    if not log_streams:\n",
    "        print(\"No log streams found. The endpoint might not have processed any requests yet.\")\n",
    "    \n",
    "    # Loop through each stream and print its recent log events\n",
    "    for stream in log_streams:\n",
    "        stream_name = stream['logStreamName']\n",
    "        print(f\"--- Logs from stream: {stream_name} ---\")\n",
    "\n",
    "        # Get log events from the stream\n",
    "        log_events = logs_client.get_log_events(\n",
    "            logGroupName=log_group_name,\n",
    "            logStreamName=stream_name,\n",
    "            startFromHead=False,  # False gets recent logs first\n",
    "            limit=50  # Get up to 50 recent log events\n",
    "        )\n",
    "        \n",
    "        # Print events in chronological order\n",
    "        for event in reversed(log_events.get(\"events\", [])):\n",
    "            print(event['message'].strip())\n",
    "        \n",
    "        print(\"-\" * (len(stream_name) + 24), \"\\n\")\n",
    "\n",
    "except logs_client.exceptions.ResourceNotFoundException:\n",
    "    print(f\"Error: Log group '{log_group_name}' was not found.\")\n",
    "    print(\"Please check the endpoint name and ensure it has been invoked.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
